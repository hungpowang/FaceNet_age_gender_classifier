{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"21-4_resnet50_mlp128_+600_aug.ipynb","provenance":[{"file_id":"11FVutJ-ji5oV_L3NQZYxD3pHZmyUdz6U","timestamp":1598945913717}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"MMWSB22LC-Ba","colab_type":"code","colab":{}},"source":["# 用單個模型同時執行兩個分類任務:\n","#   age 分成8個classes\n","#   gender 分成2個classes\n","# mlp 每個全連接層的unit個數: 128 -- 8\n","#                   \\_ 2\n","# trainning: \n","#   改用generator產生資料給fit_generator\n","#   class_weight\n","#   random_state\n","#   callback: EarlyStop, model.save\n","\n","IMG_SIZE = 224\n","BATCH_SIZE = 64\n","EPOCHS = 20\n","DROP_RATE = 0.4\n","model_folder_path = 'drive/My Drive/Tibame_AIoT_Project/face'\n","img_folder_path = 'drive/My Drive/Tibame_AIoT_Project/Datasets/cleandataset'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-bv3RgQfbZ_r","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":546},"executionInfo":{"status":"error","timestamp":1600792426525,"user_tz":-480,"elapsed":920,"user":{"displayName":"Kevin Chen","photoUrl":"","userId":"12550767145880732129"}},"outputId":"2a99f469-e6a2-4dbf-c84c-aac32d8f6a8d"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    490\u001b[0m         \"\"\"\n\u001b[0;32m--> 491\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-d5df0069828e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    249\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dfs-auth-dance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m           \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Ri1ni0ZmaYPP","colab_type":"code","colab":{}},"source":["# to measure execution time\n","!pip install ipython-autotime\n","%load_ext autotime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WIxoBByJgDOB","colab_type":"code","colab":{}},"source":["! nvidia-smi"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Enr3u7SZ0rHX","colab_type":"code","colab":{}},"source":["!pip install mtcnn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"raO3mVLfMibC","colab_type":"code","colab":{}},"source":["!pip install tensorflow==2.2.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1HiBB7Hk1Cr-","colab_type":"code","colab":{}},"source":["import scipy.io\n","import numpy as np\n","import pandas as pd\n","from datetime import datetime, timedelta\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","#import keras\n","#from keras.preprocessing.image import load_img\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\n","from keras.layers import Dense, Activation, Dropout, Flatten, Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Activation\n","from keras.layers import Conv2D, AveragePooling2D, BatchNormalization\n","from keras.models import Model, Sequential\n","from keras.regularizers import l1,l2,l1_l2\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from keras.utils import to_categorical\n","from keras import metrics\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from keras.models import load_model\n","import cv2\n","from glob import glob\n","import os\n","from mtcnn import MTCNN\n","import numpy as np"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KvutOpBGdpVr","colab_type":"code","colab":{}},"source":["print(tf.__version__)\n","print(keras.__version__)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hfiio5_KHufK","colab_type":"code","colab":{}},"source":["# 資料集由csv檔案讀入, 也可新增其他的csv檔案來擴充資料\n","# df = pd.read_csv('drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki/age_gender_wiki.csv')\n","# df_under10 = pd.read_csv('drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki/age_gender_imdb_under10.csv')\n","# df_over70 = pd.read_csv('drive/My Drive/Tibame_AIoT_Project/Datasets/資料集_IMDB-Wiki/age_gender_imdb_over70.csv')\n","# df = pd.concat([df, df_under10, df_over70])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hPi60EWkDL6K","colab_type":"code","colab":{}},"source":["# cleandata: 清除wiki資料集原本的一些年齡標註錯誤\n","df = pd.read_csv(os.path.join(img_folder_path, 'cleandata.csv'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vj29J-vpoyz","colab_type":"code","colab":{}},"source":["#some guys seem to be greater than 100. some of these are paintings. remove these old guys\n","df = df[df['age'] <= 100]\n"," \n","#some guys seem to be unborn in the data set\n","df = df[df['age'] > 0]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZI0vTSSFtF3o","colab_type":"code","colab":{}},"source":["# 每10歲分一類,70歲以上歸為同一類,共8類\n","df['age_grp'] = pd.cut(df['age'], bins=[0,10,20,30,40,50,60,70,110], right=False)\n","le = LabelEncoder()\n","le.fit(df['age_grp'].astype('str'))\n","df['age_cls'] = le.transform(df['age_grp'].astype('str'))\n","df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wBOpqcMoS90h","colab_type":"code","colab":{}},"source":["df['age_cls'].value_counts().sort_index()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ynsfUWLDp4r7","colab_type":"code","colab":{}},"source":["histogram_age = df['age_cls'].hist(bins=df['age_cls'].nunique())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SC37vJjo_AB_","colab_type":"code","colab":{}},"source":["histogram_gender = df['gender'].hist(bins=df['gender'].nunique())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HW4fp3zW99L8","colab_type":"code","colab":{}},"source":["s = df.groupby(['gender'])['age_grp'].value_counts()\n","print(s.index)\n","print(s.values)\n","s = s.sort_index()\n","s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ks6bHLoBLQYx","colab_type":"code","colab":{}},"source":["#因資料不平均, 且多輸出分類器不能用class_weight, 所以只用部分資料來訓練\n","FULL_DATA = 0\n","per_cls_trn = 600\n","# class:     f0  f1  f2   f3  f4  f5   f6  f7  m0  m1  m2   m3   m4   m5   m6   m7\n","start_idx = [0, 600, 600, 600, 0, 600, 600, 0, 0, 600, 600, 600, 600, 600, 600, 600]\n","end_idx = np.array(start_idx) + per_cls_trn\n","print(start_idx, end_idx)\n","per_cls_eval = 100\n","#用全部資料\n","#FULL_DATA = 1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSCJlWc444MN","colab_type":"code","colab":{}},"source":["#先用少量資料比較不同模型:\n","#每個類別各取部分資料,用train_test_split來切train and test\n","df_f0 = df[(df['age_cls'] == 0) & (df['gender'] == 0)]\n","df_f1 = df[(df['age_cls'] == 1) & (df['gender'] == 0)]\n","df_f2 = df[(df['age_cls'] == 2) & (df['gender'] == 0)]\n","df_f3 = df[(df['age_cls'] == 3) & (df['gender'] == 0)]\n","df_f4 = df[(df['age_cls'] == 4) & (df['gender'] == 0)]\n","df_f5 = df[(df['age_cls'] == 5) & (df['gender'] == 0)]\n","df_f6 = df[(df['age_cls'] == 6) & (df['gender'] == 0)]\n","df_f7 = df[(df['age_cls'] == 7) & (df['gender'] == 0)]\n","df_m0 = df[(df['age_cls'] == 0) & (df['gender'] == 1)]\n","df_m1 = df[(df['age_cls'] == 1) & (df['gender'] == 1)]\n","df_m2 = df[(df['age_cls'] == 2) & (df['gender'] == 1)]\n","df_m3 = df[(df['age_cls'] == 3) & (df['gender'] == 1)]\n","df_m4 = df[(df['age_cls'] == 4) & (df['gender'] == 1)]\n","df_m5 = df[(df['age_cls'] == 5) & (df['gender'] == 1)]\n","df_m6 = df[(df['age_cls'] == 6) & (df['gender'] == 1)]\n","df_m7 = df[(df['age_cls'] == 7) & (df['gender'] == 1)]\n","# train and val data\n","if FULL_DATA == 1:\n","    #每個類別保留最後per_cls_eval筆資料作為evaluate用\n","    train_df = pd.concat([\n","        df_f0[:-per_cls_eval], df_f1[:-per_cls_eval], df_f2[:-per_cls_eval], df_f3[:-per_cls_eval], \n","        df_f4[:-per_cls_eval], df_f5[:-per_cls_eval], df_f6[:-per_cls_eval], df_f7[:-per_cls_eval], \n","        df_m0[:-per_cls_eval], df_m1[:-per_cls_eval], df_m2[:-per_cls_eval], df_m3[:-per_cls_eval], \n","        df_m4[:-per_cls_eval], df_m5[:-per_cls_eval], df_m6[:-per_cls_eval], df_m7[:-per_cls_eval]         \n","        ])           \n","else:    \n","    #每個類別取同樣數量的資料來訓練\n","    train_df = pd.concat([\n","        df_f0[start_idx[0]:end_idx[0]], df_f1[start_idx[1]:end_idx[1]], df_f2[start_idx[2]:end_idx[2]], df_f3[start_idx[3]:end_idx[3]], \n","        df_f4[start_idx[4]:end_idx[4]], df_f5[start_idx[5]:end_idx[5]], df_f6[start_idx[6]:end_idx[6]], df_f7[start_idx[7]:end_idx[7]], \n","        df_m0[start_idx[8]:end_idx[8]], df_m1[start_idx[9]:end_idx[9]], df_m2[start_idx[10]:end_idx[10]], df_m3[start_idx[11]:end_idx[11]], \n","        df_m4[start_idx[12]:end_idx[12]], df_m5[start_idx[13]:end_idx[13]], df_m6[start_idx[14]:end_idx[14]], df_m7[start_idx[15]:end_idx[15]]         \n","        ])\n","    \n","# evaluate data: 每個類別保留最後per_cls_eval筆資料作為evaluate用\n","eval_df = pd.concat([\n","        df_f0[-per_cls_eval:], df_f1[-per_cls_eval:], df_f2[-per_cls_eval:], df_f3[-per_cls_eval:], \n","        df_f4[-per_cls_eval:], df_f5[-per_cls_eval:], df_f6[-per_cls_eval:], df_f7[-per_cls_eval:],\n","        df_m0[-per_cls_eval:], df_m1[-per_cls_eval:], df_m2[-per_cls_eval:], df_m3[-per_cls_eval:], \n","        df_m4[-per_cls_eval:], df_m5[-per_cls_eval:], df_m6[-per_cls_eval:], df_m7[-per_cls_eval:]         \n","        ])\n","x_eval = np.array(eval_df['full_path'])\n","# 先把模型的兩個輸出的答案合併\n","y_eval = np.array(pd.concat([eval_df['age_cls'], eval_df['gender']], axis=1))\n","print(\"train:\", len(train_df), \"predict:\", len(eval_df))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"PQi3zwjxagcW","colab":{}},"source":["# 處理答案 把它轉成one-hot (後面再做)\n","# y_train_category = to_categorical(df['age_cls'], num_classes=8)\n","\n","# 2個輸出: age, gender\n","y_df = pd.concat([pd.DataFrame(train_df['age_cls']), pd.DataFrame(train_df['gender'])], axis=1)\n","\n","# 切分訓練data\n","x_train, x_test, y_train, y_test = train_test_split(np.array(train_df['full_path']), np.array(y_df), test_size=0.2, random_state=0)\n","\n","print(x_train[0], x_test[0], y_train[0], y_test[0])\n","print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FZJoKwSbtpb8","colab_type":"code","colab":{}},"source":["detector = MTCNN()\n","#feature_extractor = load_model(os.path.join(model_folder_path, 'facenet_keras.h5'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DypYAJ7cJlrC","colab_type":"code","colab":{}},"source":["# VGGFace: https://github.com/rcmalli/keras-vggface\n","!pip install keras_vggface\n","!pip install keras_applications\n","\n","from keras_vggface.vggface import VGGFace\n","from keras_vggface.utils import preprocess_input\n","feature_extractor = VGGFace(model='vgg16', include_top=False, \n","            input_shape=(224, 224, 3), pooling='avg')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fOgsPn1i3E21","colab_type":"code","colab":{}},"source":["feature_extractor.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7iJ6QxgZ_8iI","colab_type":"code","colab":{}},"source":["# 固定pre-train model的參數\n","for lyr in feature_extractor.layers:\n","    lyr.trainable = False\n","\n","# BN\n","x = BatchNormalization()(feature_extractor.output)    \n","    \n","# MLP    \n","# x = Flatten()(x)\n","\n","# if DROP_RATE != 0:\n","#     x = Dropout(DROP_RATE)(x)\n","# x = Dense(units=512, activation='relu', kernel_regularizer='l1_l2')(x)\n","\n","if DROP_RATE != 0:\n","    x = Dropout(DROP_RATE)(x)\n","x = Dense(units=128, activation='relu', kernel_regularizer='l1_l2')(x)\n","\n","if DROP_RATE != 0:\n","    x = Dropout(DROP_RATE)(x)\n","age = Dense(units=8, activation='softmax', name='age', kernel_regularizer='l1_l2')(x)\n","gender = Dense(units=2, activation='softmax', name='gender', kernel_regularizer='l1_l2')(x)\n","\n","inputs = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n","# 2個輸出: age, gender\n","age_gender_model = Model(inputs=feature_extractor.input, outputs=[age, gender])   \n","age_gender_model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Hev5u-W9MLXn","colab_type":"code","colab":{}},"source":["from keras.utils import plot_model\n","plot_model(age_gender_model, show_shapes=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bs6tioz-AvmI","colab_type":"code","colab":{}},"source":["age_gender_model.compile(loss=[\"categorical_crossentropy\",\"categorical_crossentropy\"], \n","                  optimizer='adam', metrics=[{'age':'accuracy'},{'gender':'accuracy'}]) # 2個輸出: age, gender\n","\n","age_gender_model = load_model(os.path.join(model_folder_path,'21-3_resnet_mlp128_bs64_ep9_0.4746_0.9017.h5'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D-Mn0wTy5Bze","colab_type":"code","colab":{}},"source":["# # 資料預處理 for facenet?\n","# # Standardization\n","# def preprocess(imgs): \n","#     for i in range(imgs.shape[0]):\n","#         # standardization\n","#         img = imgs[i]\n","#         mean, std = img.mean(), img.std()\n","#         img = (img - mean) / std\n","#         imgs[i] = img\n","#     return imgs\n","# # Normalization\n","# def normalize(img):\n","#     return img / 255.\n","\n","# # -1 <= x <= 1\n","# def preprocess_1(imgs):\n","#     x = np.array(imgs, dtype = float)\n","#     x /= 127.5\n","#     x -= 1.\n","#     return x    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9ZHd-MLp16CC","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1600822521698,"user_tz":-480,"elapsed":2128,"user":{"displayName":"Kevin.KJ. Chen","photoUrl":"","userId":"12796042306080503480"}},"outputId":"19f7d714-e636-4115-f8b5-7dd1598be55c"},"source":["import imgaug.augmenters as iaa\n","import imgaug as ia\n","# augmentation\n","seq = iaa.Sequential([\n","    #iaa.Crop(px=(0, 16)), # crop images from each side by 0 to 16px (randomly chosen)\n","    iaa.Fliplr(0.5), # horizontally flip 50% of the images\n","    iaa.GaussianBlur(sigma=(0, 3.0)), # blur images with a sigma of 0 to 3.0\n","    #iaa.Flipud(0.5),\n","    iaa.Affine(\n","        scale={\"x\": (0.8, 1.2), \"y\": (0.8, 1.2)}\n","        # rotate=(-45, 45),\n","        # mode=ia.ALL, # edge, reflect, symmetric, warp, constant\n","        # shear=(-16,16)\n","    )\n","])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["time: 10.4 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"evAgdxQ20ICI","colab_type":"code","colab":{}},"source":["# detect face\n","def detect_faces(img):\n","    face_imgs = []\n","\n","    results = detector.detect_faces(img)\n","    # extract the bounding box from the first face\n","    # print('# of faces: ', len(results))\n","    for i in range(len(results)):\n","        x1, y1, width, height = results[i]['box']\n","        x2, y2 = x1 + width, y1 + height\n","        patch = img[y1:y2, x1:x2] # crop face\n","        face_imgs.append(patch)\n","     \n","    return face_imgs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8gr0xxA9NwP","colab_type":"code","colab":{}},"source":["from tensorflow.keras.utils import Sequence\n","class DataGenerator(Sequence):\n","    \"\"\"\n","    Generates data for Keras\n","    ref: https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n","    \"\"\"\n","    def __init__(self,\n","                 paths,\n","                 y_cls,\n","                 batch_size,\n","                 #num_classes,\n","                 shuffle=False,\n","                 augment=False):\n","        self.paths = paths\n","        self.y_cls = y_cls\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.augment = augment\n","        #self.num_classes = num_classes\n","        self.indexes = np.arange(len(self.paths))\n","        #self.class_map = {'0':0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5, '6': 6, '7': 7}\n","        self.on_epoch_end()\n","\n","    def __len__(self):\n","        'number of batches per epoch'\n","        return int(np.ceil(len(self.paths) / self.batch_size))\n","\n","    def __getitem__(self, index):\n","        'Generate one batch of data'\n","\n","        # Generate indexes of the batch\n","        idxs = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n","\n","        # Find list of IDs\n","        batch_paths = [self.paths[i] for i in idxs]\n","        batch_y = [self.y_cls[i] for i in idxs]\n","\n","        # Generate data\n","        X, y = self.__data_generation(batch_paths, batch_y)\n","\n","        return X, y\n","\n","    def on_epoch_end(self):\n","        'Updates indexes after each epoch'\n","        if self.shuffle:\n","            np.random.shuffle(self.indexes)\n","\n","    def __data_generation(self, paths, y_cls):\n","        \"\"\"\n","        Generates data containing batch_size samples\n","        \"\"\"\n","        # X = np.empty((len(paths), IMG_SIZE, IMG_SIZE, 3), dtype=np.float32)\n","        # y = np.empty((len(paths), self.num_classes), dtype=np.float32)\n","\n","        x_ori, x_norm, y_age, y_gender = [], [], [], []\n","\n","        for i, path in enumerate(paths):\n","            #print(\"idx:\", i, \"cls:\", y_cls[i], path)\n","        \n","            # 讀取圖片,切下臉的部分,並使用借來的模型的預處理方式來作預處理 \n","            try:          \n","                img = cv2.imread(os.path.join(img_folder_path,path))[:,:,::-1]\n","            except:\n","                print('imread failed:', path)\n","                continue \n","\n","            if self.augment:\n","                img = seq.augment_image(img)\n","\n","\n","\n","            faces = detect_faces(img)\n","            if len(faces) == 0 or faces[0].shape[0] == 0 or faces[0].shape[1] == 0:\n","                print(' No face')\n","                continue\n","            #print(faces[0].shape)   \n","            img_crop = cv2.resize(faces[0], (IMG_SIZE, IMG_SIZE))\n","\n","            # 使用借來的模型的預處理方式來作預處理\n","            img_pre = preprocess_input(np.array(img_crop,dtype=float))\n","            \n","            # 把原圖留下來\n","            x_ori.append(img)\n","            x_norm.append(img_pre)\n","            y_age.append(y_cls[i][0])\n","            y_gender.append(y_cls[i][1])\n","\n","            \n","\n","        # print(\"len(image_data)\",len(x_ori))\n","        # plt.figure(figsize=(10, 40))\n","        # for j,m in enumerate(x_ori):\n","        #     plt.subplot(1, BATCH_SIZE, (j%BATCH_SIZE)+1)\n","        #     plt.title(\"idx:{} y_cls:{}\".format(i_batch+j, y_cls[i_batch+j]))\n","        #     plt.axis(\"off\")\n","        #     plt.imshow(m)\n","        # plt.show() \n","\n","        \n","        # 2個輸出: age, gender  \n","        # print(type(y_age), len(y_age), y_age[:8])\n","        # print(type(y_gender), len(y_gender), y_gender[:8])\n","        y_age_category = to_categorical(y_age, num_classes=8) \n","        y_gender_category = to_categorical(y_gender, num_classes=2) \n","        # print(y_age_category)\n","        # print(y_gender_category)\n","        x_input = {'input_4':np.array(x_norm)}\n","        y_category = {'age':np.array(y_age_category), 'gender':np.array(y_gender_category)}\n","        # print(type(np.array(x_norm)), np.array(x_norm).shape)\n","        # print(type(y_category), np.array(y_age_category), np.array(y_gender_category))\n","\n","        #yield x_input, y_category\n","        return x_input, y_category"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3DidZIPzKHzS","colab_type":"code","colab":{}},"source":["# 用generator產生資料\n","generator_train = DataGenerator(x_train, y_train, batch_size=BATCH_SIZE, augment=True)\n","generator_test = DataGenerator(x_test, y_test, batch_size=BATCH_SIZE)\n","#type(generator_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZEWln4Tua3dg","colab":{}},"source":["# if FULL_DATA == 1:\n","#     age_weights = {0:12., 1:5., 2:1., 3:2., 4:3., 5:4., 6:6., 7:3.}\n","# else:    \n","#     # for temp\n","#     age_weights = {0:1., 1:1., 2:1., 3:1., 4:1., 5:1., 6:1., 7:1.}\n","\n","data_count = np.unique(np.argmax(y_train, axis=-1), return_counts=True)[1]\n","data_count\n","num_classes=8\n","age_weights = (1/data_count)*np.sum(data_count)/num_classes\n","class_weight = {i: w for i, w in enumerate(age_weights)}\n","print('class_weight', class_weight)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jc_L3HTVMio7","colab_type":"code","colab":{}},"source":["# fit_generator\n","checkpoint = ModelCheckpoint(os.path.join(model_folder_path,\"21-4_resnet_mlp128_bs64_aug_ep{epoch}_{val_age_accuracy:.4f}_{val_gender_accuracy:.4f}.h5\"), \n","               save_best_only=False, save_weights_only=False)   #Defaults: save_freq='epoch', save_weights_only=False\n","earlystop = EarlyStopping(patience=5, restore_best_weights=True)\n","#logs = age_gender_model.fit_generator(\n","logs = age_gender_model.fit( \n","        generator_train,\n","        #steps_per_epoch=len(x_train)//BATCH_SIZE,\n","        epochs=EPOCHS,\n","        validation_data=generator_test,\n","        #validation_steps=len(x_test)//BATCH_SIZE,\n","        #class_weight = class_weight,    # `class_weight` is only supported for Models with a single output.\n","        callbacks=[checkpoint, earlystop] \n","        )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uo-ObdSowPvw","colab_type":"code","colab":{}},"source":["age_gender_model.save(os.path.join(model_folder_path,'21-4_resnet_mlp128_bs64_aug_save.h5'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BrS_mOX64Uv7","colab_type":"code","colab":{}},"source":["model = load_model(os.path.join(model_folder_path,\"21-4_resnet_mlp128_bs64_aug_save.h5\"))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8_zCJfVyisiK","colab_type":"code","colab":{}},"source":["history = logs.history\n","history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ETe6gpnqjZzx","colab_type":"code","colab":{}},"source":["plt.plot(history['age_accuracy'])\n","plt.plot(history['val_age_accuracy'])\n","plt.legend(['age_accuracy', 'val_age_accuracy'])\n","plt.title('age_accuracy')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PYa3D33Gi_Yx","colab_type":"code","colab":{}},"source":["plt.plot(history['gender_accuracy'])\n","plt.plot(history['val_gender_accuracy'])\n","plt.legend(['gender_accuracy', 'val_gender_accuracy'])\n","plt.title('gender_accuracy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eibGTK-gjaTU","colab_type":"code","colab":{}},"source":["plt.plot(history['age_loss'])\n","plt.plot(history['val_age_loss'])\n","plt.legend(['age_loss', 'val_age_loss'])\n","plt.title('age_loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bMECQHoybWq0","colab_type":"code","colab":{}},"source":["plt.plot(history['gender_loss'])\n","plt.plot(history['val_gender_loss'])\n","plt.legend(['gender_loss', 'val_gender_loss'])\n","plt.title('gender_loss')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"luQDTgMI4tGl","colab_type":"code","colab":{}},"source":["!pip install keras2onnx"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lCHxkdwCDnam","colab_type":"code","colab":{}},"source":["# convert to onnx model\n","import keras2onnx\n","onnx_model = keras2onnx.convert_keras(age_gender_model, age_gender_model.name)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w-KrqZ3kEKet","colab_type":"code","colab":{}},"source":["keras2onnx.save_model(onnx_model, os.path.join(model_folder_path,'23-3_resnet_mlp512-128.onnx'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GBpYGPqZDTkT","colab_type":"code","colab":{}},"source":["# 取得要預測的圖片並做預處理\n","def get_preprocess_images(data_paths, y_data, batch_size=BATCH_SIZE):\n","    n = len(data_paths)\n","    # i = 0\n","    # data_paths = data_paths\n","    \n","    #while i < n:    \n","    x_ori, x_norm, y_age, y_gender = [], [], [], []\n","    #i_batch = i\n","    for idx in range(batch_size):\n","        path = data_paths[idx]\n","        #print(\"n:\", n, \"idx:\", i, \"cls:\", y_data[i], path)\n","    \n","        # 讀取圖片,切下臉的部分,並使用借來的模型的預處理方式來作預處理 \n","        try:          \n","            img = cv2.imread(os.path.join(img_folder_path,path))[:,:,::-1]\n","        except:\n","            print('imread failed:', path)\n","            idx = idx + 1\n","            continue                   \n","        \n","        faces = detect_faces(img)\n","        if len(faces) == 0 or faces[0].shape[0] == 0 or faces[0].shape[1] == 0:\n","            print('No face')\n","            idx = idx + 1\n","            continue   \n","        # print(faces[0].shape)    \n","        img_crop = cv2.resize(faces[0], (IMG_SIZE, IMG_SIZE))\n","        \n","\n","        # 使用借來的模型的預處理方式來作預處理\n","        img_pre = preprocess_input(np.array(img_crop, dtype=float))\n","\n","        # 把原圖留下來\n","        x_ori.append(img)\n","        x_norm.append(img_pre)\n","        if len(y_data) != 0:\n","            y_age.append(y_data[idx][0])\n","            y_gender.append(y_data[idx][1])\n","        \n","        idx = idx + 1\n","\n","\n","    # print(\"len(image_data)\",len(x_ori))\n","    # plt.figure(figsize=(10, 40))\n","    # for j,m in enumerate(x_ori):\n","    #     plt.subplot(1, BATCH_SIZE, (j%BATCH_SIZE)+1)\n","    #     plt.title(\"idx:{} y_data:{}\".format(i_batch+j, y_data[i_batch+j]))\n","    #     plt.axis(\"off\")\n","    #     plt.imshow(m)\n","    # plt.show() \n","\n","    \n","    # 2個輸出: age, gender  \n","    # print(type(y_age), len(y_age), y_age[:8])\n","    # print(type(y_gender), len(y_gender), y_gender[:8])\n","    if len(y_data) != 0:\n","        y_age_category = to_categorical(y_age, num_classes=8) \n","        y_gender_category = to_categorical(y_gender, num_classes=2) \n","        y_category = {'age':np.array(y_age_category), 'gender':np.array(y_gender_category)}\n","    else:\n","        y_category = []\n","\n","    # print(type(np.array(x_norm)), np.array(x_norm).shape)\n","    # print(type(y_category), np.array(y_age_category), np.array(y_gender_category))\n","\n","    return np.array(x_ori), np.array(x_norm), y_category\n","    #print('while end', i, n)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ngKRFAYgS5Zd","colab_type":"code","colab":{}},"source":["# evaluate\n","#\n","# 從保留作為evaluate用的資料,用generator產生資料 to predict\n","x_ori, x_input, y_category = get_preprocess_images(x_eval, y_eval, batch_size=len(x_eval))\n","\n","# 取出圖片資料與正確答案\n","x_eval_data, y_true_age, y_true_gender = [], [], []\n","for i,x in enumerate(x_input):\n","    # print(\"x_eval_data:\", len(list(x_dict['input_4'])))\n","    x_eval_data.append(x)\n","    # print(\"y_true_age:\", y_dict['age'].argmax(axis=-1))\n","    # print(\"y_true_gender:\", y_dict['gender'].argmax(axis=-1))    \n","    y_true_age.append( (list(y_category['age'])[i].argmax(axis=-1)) )\n","    y_true_gender.append( (list(y_category['gender'])[i].argmax(axis=-1)) )\n","\n","# print(\"-------------------------\")\n","print(\"x_eval_data:\", type(x_eval_data), \"np.array:\", np.array(x_eval_data).shape, x_eval[:8])\n","print(\"y_true_age:\", y_true_age)\n","print(\"y_true_gender:\", y_true_gender)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0VkMu89Pn36","colab_type":"code","colab":{}},"source":["# predict\n","pre = age_gender_model.predict(np.array(x_eval_data))\n","#pre[0] is predicted probabilities for age\n","#pre[1] is predicted probabilities for gender\n","pred_age = pre[0].argmax(axis=-1)\n","pred_gender = pre[1].argmax(axis=-1)\n","print(\"predict age:\",pred_age)\n","print(\"predict gender:\",pred_gender)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mkfU4iT97pGb","colab_type":"code","colab":{}},"source":["len(pred_age), len(pred_gender)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6P7GHnZJ58DJ","colab_type":"code","colab":{}},"source":["from sklearn.metrics import classification_report\n","print(np.array(y_true_age).shape, np.array(pred_age).shape, np.array(y_true_gender).shape, np.array(pred_gender).shape)\n","age_target_names = [str(i) for i in range(8)]\n","gender_target_names = [str(i) for i in range(2)]\n","print(classification_report(np.array(y_true_age), np.array(pred_age), target_names=age_target_names))\n","print(classification_report(np.array(y_true_gender), np.array(pred_gender), target_names=gender_target_names))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3pFTzAkoWIiT","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix\n","pd.DataFrame(confusion_matrix(y_true_age, pred_age),\n","            index=[\"{}(真實)\".format(i) for i in range(8)],\n","            columns=[\"{}(預測)\".format(i) for i in range(8)] \n","            )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BVTIZJsXZyjn","colab_type":"code","colab":{}},"source":["pd.DataFrame(confusion_matrix(y_true_gender, pred_gender),\n","            index=[\"{}(真實)\".format(i) for i in range(2)],\n","            columns=[\"{}(預測)\".format(i) for i in range(2)] \n","            )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LdyuPoYL6Q7K","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}